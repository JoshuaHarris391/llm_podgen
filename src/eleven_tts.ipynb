{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS API test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import configparser as cp\n",
    "import pydub \n",
    "import glob\n",
    "import static_ffmpeg\n",
    "static_ffmpeg.add_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pandas requests configparser pydub static-ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/json'):\n",
    "    os.makedirs('data/json')\n",
    "    \n",
    "if not os.path.exists('data/podcast_scripts'):\n",
    "    os.makedirs('data/podcast_scripts')\n",
    "    \n",
    "if not os.path.exists('output/stems'):\n",
    "    os.makedirs('output/stems')\n",
    "    \n",
    "if not os.path.exists('output/audio_combined'):\n",
    "    os.makedirs('output/audio_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting api keys\n",
    "config = cp.ConfigParser()\n",
    "config.read('config.ini')\n",
    "eleven_api_key = config.get('api_keys', 'elevenlabs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = \"https://api.elevenlabs.io/v1/voices\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"xi-api-key\": eleven_api_key\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.status_code)\n",
    "\n",
    "data = response.json()\n",
    "with open(\"./data/json/speakers_eleven.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in podcast script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining podcast script to use\n",
    "pod_script_fn = 'lavender_jiang.txt'\n",
    "\n",
    "# Extracting basename\n",
    "pod_script_fn_base = pod_script_fn.replace('.txt', '')\n",
    "\n",
    "# Reading in script\n",
    "with open('data/podcast_scripts/' + pod_script_fn, 'r') as file:\n",
    "    pod_script = file.readlines()\n",
    "\n",
    "# extracting host and guest dialogue\n",
    "host_lines = [line for line in pod_script if line.startswith('**host:** ')]\n",
    "host_lines = [i.replace(\"**host:** \", \"\") for i in host_lines]\n",
    "host_lines = [i.strip() for i in host_lines]\n",
    "\n",
    "\n",
    "guest_lines = [line for line in pod_script if line.startswith('**guest:** ')]\n",
    "guest_lines = [i.replace(\"**guest:** \", \"\") for i in guest_lines]\n",
    "guest_lines = [i.strip() for i in guest_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to today\\'s podcast! We have a special guest with us, Dr Lavender Jiang, the author of an exciting paper titled \"Health system-scale language models are all-purpose prediction engines.\" The paper was published in Nature on June 7, 2023. Lavender, it\\'s great to have you here. Can you give us a brief overview of your paper and its main findings?',\n",
       " 'That sounds fascinating! Can you explain how NYUTron works and how it was trained?',\n",
       " \"It's impressive how you've managed to use unstructured clinical notes to train such a powerful model. What were some of the tasks you evaluated NYUTron on, and how did it perform?\",\n",
       " \"It's amazing to see how versatile NYUTron is in handling various tasks. How do you envision NYUTron being integrated into clinical workflows and assisting healthcare professionals?\",\n",
       " \"I can see how this could be a game-changer in healthcare. However, I'm curious about the generalizability of NYUTron across different clinical environments. How does it perform in different settings?\",\n",
       " \"That's great to hear! I can imagine how this technology could revolutionize healthcare by providing valuable insights and assistance to healthcare professionals. Thank you for sharing your work with us, Lavender. It's been a pleasure having you on the podcast.\"]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thank you for having me! In our paper, we show that unstructured clinical notes from electronic health records can be used to train clinical language models, which can then be applied as all-purpose clinical predictive engines. We developed a large language model called NYUTron and fine-tuned it across a wide range of clinical and operational predictive tasks. Our results demonstrate the potential of using clinical language models in medicine to provide guidance at the point of care.',\n",
       " 'Sure! NYUTron is based on a bidirectional encoder model known as BERT, and it was pretrained on a vast set of unlabelled clinical notes from the NYU Langone electronic health record system. We then fine-tuned the model for each downstream task using a masked language modeling objective, which involves masking words or subwords in clinical notes and training the model to fill in the masked word correctly.',\n",
       " 'We evaluated NYUTron on five different tasks: 30-day all-cause readmission prediction, in-hospital mortality prediction, comorbidity prediction, insurance denial prediction, and length of stay prediction. In general, NYUTron performed well across these tasks, showing its potential as an all-purpose prediction tool for clinical and operational outcomes.',\n",
       " 'We believe that clinical language models like NYUTron can be integrated seamlessly into clinical workflows, providing real-time guidance to physicians at the point of care. For example, NYUTron could help predict patient outcomes, identify potential insurance denials, or estimate the length of stay, allowing healthcare professionals to make more informed decisions and improve patient care.',\n",
       " 'We investigated the robustness of NYUTron across two geographically separated hospitals within the NYU Langone Health System. Our results showed that NYUTron can be generalized to different sites through local fine-tuning, which is a promising finding for its potential application in various healthcare settings.',\n",
       " \"Thank you for having me! I'm excited to see how clinical language models like NYUTron will continue to evolve and contribute to improving healthcare outcomes.\"]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guest_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_voice_el(input_text, speaker, api_key, outdir, filename, stability = 0, similarity_boost = 0, style = 0, speaker_boost = True):\n",
    "\n",
    "    url = 'https://api.elevenlabs.io/v1/text-to-speech/' + speaker\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"audio/mpeg\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"xi-api-key\": api_key\n",
    "    }\n",
    "    payload = {\n",
    "    \"text\": input_text,\n",
    "    \"optimize_streaming_latency\": 1,\n",
    "    \"model_id\": \"eleven_multilingual_v2\",\n",
    "    \"voice_settings\": {\n",
    "            \"stability\": stability,\n",
    "            \"similarity_boost\": similarity_boost,\n",
    "            \"style\": style,\n",
    "            \"use_speaker_boost\": speaker_boost\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open a new file in binary mode, 'wb'\n",
    "        outpath = outdir + \"/\" + filename + '.mp3'\n",
    "        print('success, writing .mp3 to ', outpath)\n",
    "        with open(outpath, 'wb') as f:\n",
    "            # Write the content of the response to the file\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        print('Request failed with status code', response.status_code)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating responses for host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success, writing .mp3 to  output/stems/lavender_jiang/host_0.mp3\n",
      "success, writing .mp3 to  output/stems/lavender_jiang/host_1.mp3\n",
      "success, writing .mp3 to  output/stems/lavender_jiang/host_2.mp3\n",
      "success, writing .mp3 to  output/stems/lavender_jiang/host_3.mp3\n",
      "success, writing .mp3 to  output/stems/lavender_jiang/host_4.mp3\n",
      "success, writing .mp3 to  output/stems/lavender_jiang/host_5.mp3\n"
     ]
    }
   ],
   "source": [
    "# Generating responses for all lines\n",
    "speaker_id = \"ZQe5CZNOzWyzPSCn5a3c\" # James\n",
    "\n",
    "# Creating directory\n",
    "if not os.path.exists('output/stems/' + pod_script_fn_base):\n",
    "    os.makedirs('output/stems/' + pod_script_fn_base)\n",
    "\n",
    "stems_output_dir = \"output/stems/\" + pod_script_fn_base\n",
    "\n",
    "for i in range(0, len(host_lines)):\n",
    "    input_text = host_lines[i]\n",
    "    print(\"INPUT == \", input_text)\n",
    "    text_to_voice_el(input_text, speaker_id, eleven_api_key, outdir=stems_output_dir, filename=\"host_\" + str(i)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating responses for guest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT ==  Thank you for having me! In our paper, we show that unstructured clinical notes from electronic health records can be used to train clinical language models, which can then be applied as all-purpose clinical predictive engines. We developed a large language model called NYUTron and fine-tuned it across a wide range of clinical and operational predictive tasks. Our results demonstrate the potential of using clinical language models in medicine to provide guidance at the point of care.\n",
      "success, writing .mp3 to  output/stems/lavender_jiang/guest_0.mp3\n",
      "INPUT ==  Sure! NYUTron is based on a bidirectional encoder model known as BERT, and it was pretrained on a vast set of unlabelled clinical notes from the NYU Langone electronic health record system. We then fine-tuned the model for each downstream task using a masked language modeling objective, which involves masking words or subwords in clinical notes and training the model to fill in the masked word correctly.\n"
     ]
    }
   ],
   "source": [
    "# Generating responses for all lines\n",
    "speaker_id = \"XrExE9yKIg1WjnnlVkGX\" # kayla\n",
    "\n",
    "for i in range(0, len(guest_lines)):\n",
    "    input_text = guest_lines[i]\n",
    "    print(\"INPUT == \", input_text)\n",
    "    text_to_voice_el(input_text, speaker_id, eleven_api_key, outdir=stems_output_dir, filename=\"guest_\" + str(i)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining mp3 files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing host files \n",
    "host_files = glob.glob(stems_output_dir + 'host_*', )\n",
    "host_files = sorted(host_files)\n",
    "\n",
    "guest_files = glob.glob(stems_output_dir + 'guest_*')\n",
    "guest_files = sorted(guest_files)\n",
    "\n",
    "# Loading files into list\n",
    "host_audio_list = [AudioSegment.from_file(i, format='mp3') for i in host_files]\n",
    "guest_audio_list = [AudioSegment.from_file(i, format='mp3') for i in guest_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x12194b310>,\n",
       " <pydub.audio_segment.AudioSegment at 0x12176f210>,\n",
       " <pydub.audio_segment.AudioSegment at 0x121b1a190>,\n",
       " <pydub.audio_segment.AudioSegment at 0x12199a0d0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x121948b90>,\n",
       " <pydub.audio_segment.AudioSegment at 0x121b1b610>,\n",
       " <pydub.audio_segment.AudioSegment at 0x12199bb90>,\n",
       " <pydub.audio_segment.AudioSegment at 0x12199ac50>,\n",
       " <pydub.audio_segment.AudioSegment at 0x121999750>,\n",
       " <pydub.audio_segment.AudioSegment at 0x1219992d0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x12176c6d0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x1218b0710>,\n",
       " <pydub.audio_segment.AudioSegment at 0x12176fd90>,\n",
       " <pydub.audio_segment.AudioSegment at 0x1219995d0>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interleaving and concatneating audio files \n",
    "combined_list = []\n",
    "for i in zip(host_audio_list, guest_audio_list):\n",
    "    combined_list.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='test.mp3'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exporting\n",
    "\n",
    "final_sound = AudioSegment.empty()\n",
    "\n",
    "for i in combined_list:\n",
    "    final_sound += i\n",
    "\n",
    "# Creating directory\n",
    "if not os.path.exists('output/audio_combined/' + pod_script_fn_base):\n",
    "    os.makedirs('output/audio_combined/' + pod_script_fn_base)\n",
    "\n",
    "audio_combined_outdir = 'output/audio_combined/' + pod_script_fn_base + '_output_audio.mp3'\n",
    "final_sound.export(audio_combined_outdir, format = 'mp3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
